---
title: "Big Money, Big Money"
output: 
  html_document:
    theme: 'cerulean'
    toc: true
    toc_float: true
    toc_depth: '2'
    code_folding: hide
    df_print: paged
---

<!-- increasing text size for whole document -->
<style type="text/css">

body, td {
   font-size: 17px;
}
</style>

<!-- Styling for blue banner -->
<style>
div.blue { background-color:#4d79ff; 
           border-radius: 5px; 
           padding: 10px;
           color: white;
           }
</style>

<!-- Styling for tabset background -->
<style>
div.back { background-color: white;
  border: 1px solid lightgray;
  padding: 3px;
  margin: 20px;
           }
</style>


```{r, setup, include=FALSE}
knitr::opts_chunk$set(comment = NA, warning = FALSE, message=FALSE)
infile.csv = "BonusPuzzles.csv"
```

<h1> <div  class="blue">  Introduction  </div> </h1>



Game shows provide contestants a quick way to win lots of cash and prizes. Many game shows have a final round where contestestants have an opportunity to quickly increase their winnings. In Wheel of Fortune this final round is known as the Bonus Round. The Bonus Round gives the show's winner one final puzzle. To help solve the Bonus Puzzle the contestant selects a Category and the letters *R, S, T, L, N, E* are revealed. The contestant then gets to choose 3 more consonants and 1 vowel; The contestants gets a fourth consonant if they won the wild card in a prior round. The goals of this analysis are to determine:

+ What categories occur most often and are the hardest?
+ What letters are most commonly chosen?  
+ What letters should be chosen?  
+ What is the role of repeating consecutively letters? (Ex. "HELLO" contains back to back L's)  
+ How much of an advantage is the Wild Card?  

These questions were picked from my own curiosity and personal interests. Wheel of Fortune is one of my favorite shows, and I watch it often. Being a fan of the show, I have often wondered whether contestants are maximizing their probability of success, and I want to have a plan in case I get to be on the show someday. 

***
This analysis is segemented into four main sections:  

+ **Prequisites**: Loading packages, defining custom functions, reading in data
+ **Data**: Explanation of Data collection, format, cleaning
+ **Research** Questions: Investigation into each research question; Subsections for each Question
+ **Conclusion and Further Research**: Summarize findings and discuss issues, possible improvements, and future ideas

<h1> <div  class="blue">  Prerequisites  </div> </h1>

***
Below are the required R packages, custom functions, and steps for reading in the dataset.

```{r class.source='fold-show', echo=TRUE, results='hide'}
require(tidyverse)
require(lubridate)
require(ggpubr)
require(knitr)
require(kableExtra)

appears_in_puzzle = function(x){
  #function determines whether letter appears in puzzle
  
  return(x>0)
}


find_double = Vectorize(
  #function that returns letters that appear consecutively in a string
  # find_double("Hello") returns "L"
  
  function(.data){
    .data=toupper(.data)
    tmp = ""
    for(i in toupper(letters)){
      if(str_detect(.data, paste("[", i, "]","{2}", sep=""))){
        tmp = str_glue(tmp, paste(i," ", sep = ""))
      }
    }
    if(tmp == "")
      return(tmp)
    else
      return(trimws(tmp))
  }
)

dat = infile.csv
WOF = as_tibble(read.csv(dat, header=TRUE, stringsAsFactors = FALSE))
```

<h1> <div  class="blue">  Data  </div> </h1>

I gathered the data using a webscraper I created. I scraped data from this Angelfire __[Website](https://www.angelfire.com/mi4/malldirectories/wheel/wheelbonus.html)__ titled "The Wheel of Fortune Bonus Puzzle Compendium." I only used information from 2007-2015, because information on all puzzles was known.

<h2> Data Cleaning </h2>
***
The data was relatively clean, but there were some minor issues that needed to be fixed.The structure of the data is shown below.

```{r}
str(WOF)
```

It's worth noting that there are 1754 observations of 9 variables:

+ DATE: Date show aired
+ CATEGORY: Puzzle Category
+ PUZZLE: Solution to the Bonus Puzzle
+ L1-L5: Letters selected by contestant. Typically the vowel is selected last(L4). L5 contains NAs because only contestants with the Wild Card get to select a fifth letter
+ WIN: Indicates whether the contestant won

Below some minor issues that I discovered were corrected. DATE was converted, and some minor issues with the input of rows was corrected.

```{r}
WOF = WOF %>% mutate(DATE = ymd(DATE))

WOF$L2[1563] = "D"# was coded as D?

#L4 was NA and L5 was not, so I switched them
WOF$L4[610] = "A"
WOF$L5[610] = NA
```

<h2> Exploratory Data Analysis </h2>
***
Determining the number of unique puzzles.

```{r class.source='fold-show', echo=TRUE}
length(unique(WOF$PUZZLE))
```

1710 is less than the number of observations, so some puzzle solutions were repeated. I needed to determine whether this is because the show reused puzzles multiple times, or is it because of reruns/compiling error. We see that each repeated puzzle has different guesses, so this means the show will reuse puzzles. No adjustment to the data is needed


```{r}
# Puzzles that have been repeated
repeats = WOF %>%
  group_by(PUZZLE) %>%
  summarize(num = n()) %>%
  filter(num>1) %>%
  select(PUZZLE)

# puzzles are used multiple times. Same puzzle different letters chosen
reps = WOF %>%
  filter(PUZZLE %in% repeats$PUZZLE) %>%
  select(-CATEGORY)%>%
  arrange(PUZZLE)

scroll_box(kable_styling(kable(reps), bootstrap_options = 's'), height = '400px')
```


<h1> <div  class="blue">  Research Questions  </div> </h1>
To answer the research questions, the data needs to be transformed, subsetted, and altered into a more user friendly format containing counts of each letter. The changes are shown below.

```{r class.source='fold-show'}
# How often does each letter appear in the puzzle
num_appearance = WOF %>%
  mutate(num_A = str_count(PUZZLE, "A"),
         num_B = str_count(PUZZLE, "B"),
         num_C = str_count(PUZZLE, "C"),
         num_D = str_count(PUZZLE, "D"),
         num_E = str_count(PUZZLE, "E"),
         num_F = str_count(PUZZLE, "F"),
         num_G = str_count(PUZZLE, "G"),
         num_H = str_count(PUZZLE, "H"),
         num_I = str_count(PUZZLE, "I"),
         num_J = str_count(PUZZLE, "J"),
         num_K = str_count(PUZZLE, "K"),
         num_L = str_count(PUZZLE, "L"),
         num_M = str_count(PUZZLE, "M"),
         num_N = str_count(PUZZLE, "N"),
         num_O = str_count(PUZZLE, "O"),
         num_P = str_count(PUZZLE, "P"),
         num_Q = str_count(PUZZLE, "Q"),
         num_R = str_count(PUZZLE, "R"),
         num_S = str_count(PUZZLE, "S"),
         num_T = str_count(PUZZLE, "T"),
         num_U = str_count(PUZZLE, "U"),
         num_V = str_count(PUZZLE, "V"),
         num_W = str_count(PUZZLE, "W"),
         num_X = str_count(PUZZLE, "X"),
         num_Y = str_count(PUZZLE, "Y"),
         num_Z = str_count(PUZZLE, "Z"))


#percentage of puzzles each letter appears in
percent_appears = num_appearance %>%
  apply(., 2, appears_in_puzzle) %>%
  as.data.frame() %>%
  summarize_at(vars(num_A:num_Z), mean) %>%
  pivot_longer(
    cols = num_A:num_Z, 
    names_to = "Letter", 
    values_to = "Percent") 

#Expected Value for each letter
ExpVal = num_appearance %>%
  summarize_at(vars(num_A:num_Z), mean) %>%
  pivot_longer(
    cols = num_A:num_Z, 
    names_to = "Letter", 
    values_to = "ExpVal") 
```

## What Categories Occur Most Often and Are the Hardest {.tabset .tabset-fade}
***
In total 24 different categories were used. Some of these categories are plurals of the same categories(Thing and Things). Of the 24, the most common categories only 9 were used more than 30 times, with "Phrase" and "Thing/Things" being by far the most common.



```{r}
c("Num_Categories" = length(unique(WOF$CATEGORY)))
```

<div class = "back">

```{r}
tab = sort(c(table(WOF$CATEGORY)[which(table(WOF$CATEGORY)>30)]), 
           decreasing= TRUE)

kable_styling(
  kable(tab, col.names = "Count"),bootstrap_options = c('c','s'),row_label_position = 'c')
```
</div>

If we perform a chi-square test of independence, we can determine if the category is independent of puzzle difficulty. We can calculate the expected number of wins using the overall and win probability and the number of times each category appeared. A category with fewer wins than expected indicates a tougher category. The null and alternative hypotheses for our chi-square test are: 

$$  H_0: \text{Variables are independent} \\ 
    H_1: \text{Variables are dependent}
$$

To ensure all assumptions of the chi-square test are met, only categories with greater than 30 appearances will be used. 


### Chi-Square Test

<div class = "back">  
```{r}
#Extracting names and subbsetting based on the common categories
common_cats = names(table(WOF$CATEGORY)[which(table(WOF$CATEGORY)>30)])
cat_wins = WOF %>% 
  filter(CATEGORY %in% common_cats) %>%
  select(WIN, CATEGORY)

#performing the chi-square test
(x = chisq.test(x = cat_wins$WIN, y=cat_wins$CATEGORY))
```
</div>


### Expected Values  
<div class = "back">
```{r}
t(x$expected) # assumptions met all >5
```
</div>


### Residuals  
<div class = "back">
```{r}
# shows which puzzles have fewer wins than expected
# (negative residuals in win column => harder)
t(x$residuals)
```
</div>

## {-}

The output above indicates rejection of the null hypothesis and that the variables are not independent(p-value = .01441), i.e. the probability of winning changes based on category. All expected values are greater than 5, and it is reasonable to  assume each puzzle is independent from one another. The standardized residual table shows the hardest categories are 'Thing/s' and 'People'. These have the largest negative values in the 'Yes' column. The easiest categories are 'Phrase' and 'Food & Drink.'




<h2> What Letters Appear Most Often? </h2>
***
I want to see which letters appear in the Bonus Puzzle the most.

```{r}
num_app = num_appearance %>%
  summarize_at(vars(num_A:num_Z), sum) %>%
  pivot_longer(
    cols = num_A:num_Z,
    names_to = "Letter", 
    values_to = "Count"
  ) %>%
  mutate(Given = if_else(str_detect(Letter, "[RSTLNE]"), T, F),
         Label = str_extract(Letter, "[:upper:]")) %>%
  left_join(percent_appears, by =c("Letter"="Letter")) %>%
  left_join(ExpVal, by =c("Letter"="Letter")) %>%
  ggplot(aes(x=reorder(Label, Count))) + 
  geom_bar(stat = "identity", aes(y=Count, fill=Given)) +
  geom_line(aes(y=1899*Percent, group=1)) +
  geom_point(aes(y=1899*Percent)) +
  xlab(label = "") + ylab("Letter Appearances") +
  labs(title = "Number of Letter Appearance and \nPercentage of Puzzles Containing Letter")+
  scale_y_continuous(
    trans= 'reverse',
    sec.axis = sec_axis(~./1899,breaks = seq(0,1,.2), name = "% of Puzzles"),
    breaks = seq(0, 1899, length.out = 6),
    labels = c("0","400","800","1200","1600","2000")) +
  guides(fill=FALSE) +
  theme(axis.text.y = element_blank(),
       axis.ticks.y = element_blank(),
       plot.margin=unit(c(0,0,0,0),"cm")) +
coord_flip()
  

#Expected number of times a letter appears in each puzzle
ExVal=ExpVal %>%
mutate(Label = str_extract(Letter,"[:upper:]"),
      Given = if_else(str_detect(Letter, "[RSTLNE]"), T, F)) %>%
ggplot(aes(x=reorder(Label, ExpVal), y=ExpVal, fill=Given)) + 
geom_bar(stat="identity") +
xlab("") + 
scale_y_continuous(breaks = seq(0,1,.2))+
labs(title = "\nExpected Value of Each Letter\n\n") +
geom_text(aes(label=round(ExpVal,2), 
             y=if_else(ExpVal>1,ExpVal-.05, ExpVal+.05))) +
guides(fill=FALSE) +
theme(plot.margin=unit(c(0,0,0,0),"cm"))+
coord_flip()
```

<div class = "back">
```{r}
ggarrange(num_app, ExVal, ncol=2)
```
</div>

The left bar chart above shows the most common letters and the line shows the percentage of puzzles in which the letter appears. The given letters (*R, S, T, L, N, E*) are shown in blue. Not surprisingly, the four most common letters are vowels. We also see that the given letters(blue bars) are all in the top 13 most used letters. I would think the consonants given the most common in the English language, so maybe they choose puzzles that don't contain them. This chart suggests a contestant should select *H, G, P and O* to reveal the most letters on average.
The chart on the right shows the number of times each letter is expected to appear in every puzzle. This means if we select *H, G, P* and *O* on average about 2.5 letters will be revealed. 


<h2> What Letters Are Chosen Most Often? </h2>
***

I wanted to see if contestants were selecting the most frequently appearing letters.

<div class = "back">
```{r}
num_guessed =tibble(
  Guesses = table(c(WOF$L1, WOF$L2, WOF$L3, WOF$L4, WOF$L5), useNA = "always"),
  Letter = names(table(c(WOF$L1, WOF$L2, WOF$L3, WOF$L4, WOF$L5), useNA = "always"))) %>%
  mutate(Guesses = as.numeric(Guesses))

  ggplot(data=num_guessed, aes(x=reorder(Letter, -Guesses), y=Guesses)) +
    geom_bar(stat="identity", fill = "#F8766D") +
    labs(
      title = "Number of Times Letter Was Guessed",
      subtitle = "NA indicates Wild Card was not used") +
    xlab("")
    
```
</div>

The chart above shows the most common letters chosen are *C, M, D, A*. Other than *A* none of these letters appear the top 50% of most used letters. This suggests most people are not maximizing the selections. If a contestant chose *C, M, D, A* s/he could expect 1.91 letters on average; more than half a letter less than the optimum selection *H, G, P, O*. I now want to check whether these two letter groups had different win percentages.

```{r}
HGPA = c("H", "G", "P", "O")
CMDA = c("C", "M", "D", "A")
rbind(
HGPA = WOF %>%
  filter(L1 %in% HGPA & L2 %in% HGPA & L3 %in% HGPA & L4 %in% HGPA) %>%
  summarize(Count = n(), "Win%" = mean(WIN == "Yes")),

CMDA = WOF %>%
  filter(L1 %in% CMDA & L2 %in% CMDA & L3 %in% CMDA & L4 %in% CMDA) %>%
  summarize(Count = n(), "Win%" = mean(WIN=="Yes"))
)
```

The number of contestants who selected each of these selections is shown above. We see many more contestants chose *C, M, D, A*, but there does not appear to be a significant difference in win percentage. Larger sample sizes may be needed to make a definitive statement.


<h2> What Is the Effect of Double Letters? </h2>
***

English words often contain consecutive repeating letters. In my experience a puzzle is much harder to solve when there are repeating consecutive letters(double letters) that are not known. I want to see what letters appear consecutively most often and if puzzles that have unknown double letters are harder. 

Below is the number of times each letter appears consecutively and the count and winning percentage of puzzles with and without double letters.

<div class = "back">
```{r}
#gathering counts each table appears consecutively, plotting
WOF %>%
  mutate(Double = find_double(PUZZLE)) %>%
  separate(Double, c("R1", "R2", "R3"), sep = " ", remove = F) %>%
  select(c(WIN,R1:R3)) %>% 
  pivot_longer(R1:R3, values_to = "Letter") %>%
  filter((!is.na(Letter)) & Letter != "" ) %>%
  group_by(Letter) %>%
  summarize(Count = n()) %>%
ggplot(aes(x=reorder(Letter, -Count), y=Count)) +
geom_col(fill = "#F8766D") +
xlab("") + ylab("Number of Puzzles") +
labs(title = "Letters Appearing Twice In A Row") +
geom_text(aes(label=Count, y=Count+2))
```
</div>

```{r}
# how many puzzles contain double letters and how often do they win?
double_winners = WOF %>%
  mutate(Double = find_double(PUZZLE)) %>%
  separate(Double, c("R1", "R2", "R3"), sep = " ", remove = F) %>%
  select(c(DATE,WIN,R1:R3)) %>%
  filter(str_detect(R1, "[A-Z]")) 
  
# Puzzles without double letters and how often are they won
no_doubles_winners = WOF[match(WOF$DATE, double_winners$DATE, nomatch = FALSE) == 0, ]   
 

Doubles = double_winners %>% 
  summarize(Count = n(), "win%" = mean(WIN == "Yes"))
No_Doubles = no_doubles_winners %>% 
  summarize(Count = n(), "win%" = mean(WIN == "Yes"))

cbind(Puzzle = c("Doubles", "No Doubles"), rbind(Doubles, No_Doubles))
```

The results above show the letters *O, F*, and *P* are the letters appearing consecutively most often. There my be a slight decrease in win percentage in puzzle that contain doubles letters. Again, a hypothesis test was performed to determine whether this decrease is significant.

$$ H_0: \text{Puzzles with double letters are of equal difficuly} \\ 
   H_1: \text{Puzzles with double letters are of higher difficulty} 
$$

This is a one sided test because I am only concerned with the difficulty increasing in puzzles with double letters.

```{r}
x1 = sum(double_winners$WIN == "Yes")
x2 = sum(no_doubles_winners$WIN == "Yes")
n1 = length(double_winners$WIN)
n2 = length(no_doubles_winners$WIN)

prop.test(c(x1,x2), c(n1,n2),alternative = "l", correct=F) 
```

If we use a significance level of 95% we will fail to reject the null hypothesis. The p-value is still relatively small (.07284), so there is some evidence double letter puzzles are harder. I personally would not want a puzzle containing a double letter.

What if the contestant successfully guesses a double letter? Is s/he more likely to win? A one sided hypothesis test was performed again.

```{r}
doubles = WOF %>%
  mutate(Double = find_double(PUZZLE),
         GUESSES = if_else(is.na(L5), 
                           paste(L1,L2,L3,L4,sep=""), 
                           paste(L1,L2,L3,L4,L5,sep=""))) %>%
  separate(col = Double, into=c("D1", "D2", "D3"), remove = FALSE) %>%
  filter(str_detect(GUESSES, D1) | str_detect(GUESSES, D2) | str_detect(GUESSES, D3))

no_doubles = WOF[(match(WOF$DATE, doubles$DATE, nomatch = FALSE) == 0),]
  
rbind(Doubles = doubles %>% summarize(count = n(), "win%" = mean(WIN == "Yes") ),#396
      No_Doubles = no_doubles %>% summarize(count = n(), "win%" = mean(WIN == "Yes")))


#if guessed a double letter, are you more likely to win? YES, maybe because 
# contested knew before guessing
x1 = sum(doubles$WIN == "Yes")
x2 = sum(no_doubles$WIN == "Yes")
n1 = length(doubles$WIN)
n2 = length(no_doubles$WIN)

prop.test(c(x1,x2), c(n1,n2), correct=F, alternative = 'g') 

```

This hypothesis suggests if a contestant successfully guesses a double letter their chance of winning significantly improves(p-value < 0.0001). Even though successfully guessing a double letter significantly improves winning percentage, hunting double letters may not be a valid strategy as double letters only appear in about 23% of puzzles.


<h2> Does the Wild Card Increase Winning Percentage? </h2>
***

The Wild Card may provide the contestant an edge. If the contestant possesses the Wild Card s/he is granted an extra consonant. The number of contestants who had the Wild Card and a two-proportion hypothesis test are shown below. This is again a one-sided test, because I think the winning percentage will increase if the contestant has the Wild Card.

```{r class.source='fold-show'}
wild = WOF %>%
  filter(!is.na(L5))

length(wild$WIN)
```

```{r}
no_wild = WOF %>%
  filter(!(DATE %in% wild$DATE))

x1 = sum(wild$WIN == "Yes")
x2 = sum(no_wild$WIN == "Yes")
n1 = length(wild$WIN)
n2 = length(no_wild$WIN)

prop.test(c(x1,x2), c(n1,n2), correct = F, alternative = 'g') 
```


These results show only a small percent(~12%) of contestants had the Wild Card. There is evidence that the Wild Card statistically increases the percentage of winning (p-value = 0.03484). Obtaining the Wild Card is basically luck, although you will have more spins to gain the Wild Card if you are a skilled player.

<h1> <div  class="blue">  Conclusions  </div> </h1>

This study analyzed the results of Bonus Puzzles in the game show Wheel of Fortune. The questions, solutions, and suggested strategies are shown below:

+ **What categories occur most often and are the hardest?**
  - The most common categories are Thing/s, Phrase, and Person.
  - The most difficult categories are Thing/s and People. The easiest categories are Phrase and Food & Drink 

+ **What letters appear most often?**
  - The most frequently occuring consonants are *T, R, N, H*, and *G*.
  - The optimal choice of letters is *H, G, P*, and *O*.

+ **What letters do contestants select most often?**
  - The most common consonants are *C, M, D*, and *P*.
  - The most common vowel selected is *A*.
  - On average contestants do not select the optimal letters.

+ **What is the effect of double letters?**
  - The most frequent double letters are *O, F*, and *P*.
  - Double letters occur in approximately 23% of puzzles.
  - There is some evidence puzzles with double letters are harder (p-value = 0.07284).
  
+ **Does the Wild Card increase Winning Percentage?**
  - Contestants had the wild card 206 times(~12%).
  - There is some evidence the wild card significantly improves winning percentage (p-value = 0.03484)


This study is could be improved if more recent data was available. The data for this study was from 2007-2015. This would allow for more recent changes to the game to be examined. WOF regularly adds new categories and rules. For example, in 2017, contestants began having the choice of three categories in the bonus round. This could skew the most common category. I would also like to study other rounds including toss-ups and the prize puzzle, but I was unable to acquire this data.

In general, I think this study provides interesting insight into the Wheel of Fortune Bonus Puzzle. While data may be a bit dated, it still provides good insight on what letters and categories to choose and avoid.
